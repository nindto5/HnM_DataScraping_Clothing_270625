{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a868e61f-1644-4abc-add0-60f57b2cf4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a3932e-32ff-4477-9d4b-a34b99862ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping product listing page 1...\n",
      "Error during product listing request on page 1: 422 Client Error: Unprocessable Entity for url: https://api.hm.com/search-services/v1/id_id/listing/resultpage?pageSource=PLP&page=1&sort=RELEVANCE&pageId=%2Fladies%2Fshop-by-product%2Fview-all&page-size=36&categoryId=ladies_all&filters=sale%3Afalse%7C%7ColdSale%3Afalse&touchPoint=DESKTOP&skipStockCheck=false\n",
      "Finished scraping 0 raw product entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Supplier Details: 0product [00:00, ?product/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "DataFrame columns:\n",
      "RangeIndex(start=0, stop=0, step=1)\n",
      "Data saved to HnM_CLOTHING_LADIES_INDO_020725.csv. Total products with data: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# API calls\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8,id;q=0.7,ms;q=0.6',\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'Origin': 'https://www2.hm.com',\n",
    "    'Pragma': 'no-cache',\n",
    "    'Priority': 'u=1, i',\n",
    "    'Referer': 'https://www2.hm.com/',\n",
    "    'Sec-Ch-Ua': '\"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand\";v=\"24\"',\n",
    "    'Sec-Ch-Ua-Mobile': '?0',\n",
    "    'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',\n",
    "    'X-Customer-Key': 'd150a6cc-6e04-4804-8447-3ab67460a1d9',\n",
    "    'X-Session-Key': 'd150a6cc-6e04-4804-8447-3ab67460a1d9',\n",
    "}\n",
    "\n",
    "# Base URL\n",
    "product_list_base_url = 'https://api.hm.com/search-services/v1/id_id/listing/resultpage'\n",
    "\n",
    "# Base URL supplier details GET request\n",
    "supplier_detail_base_url = 'https://www2.hm.com/id_id/supplierDetails/articles/'\n",
    "\n",
    "# Base parameters\n",
    "base_params = {\n",
    "    'pageSource': 'PLP',\n",
    "    'page': 1, \n",
    "    'sort': 'RELEVANCE',\n",
    "    'pageId': '/ladies/shop-by-product/view-all',\n",
    "    'page-size': 36,\n",
    "    'categoryId': 'ladies_all',\n",
    "    'filters': 'sale:false||oldSale:false',\n",
    "    'touchPoint': 'DESKTOP',\n",
    "    'skipStockCheck': 'false',\n",
    "}\n",
    "\n",
    "# Max retries for a request\n",
    "RETRY_MAX = 5\n",
    "# Status codes to retry on (400 Client Error, 5xx Server Errors, etc)\n",
    "RETRY_STATUS_FORCELIST = [400, 401, 403, 404, 408, 429, 500, 502, 503, 504]\n",
    "RETRY_BACKOFF_FACTOR = 0.5 # 0.5, 1, 2, 4, 8 seconds\n",
    "\n",
    "session = requests.Session()\n",
    "retries = Retry(total=RETRY_MAX,\n",
    "                backoff_factor=RETRY_BACKOFF_FACTOR,\n",
    "                status_forcelist=RETRY_STATUS_FORCELIST,\n",
    "                allowed_methods=frozenset(['GET', 'POST']))\n",
    "\n",
    "session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "\n",
    "# --- Product Listing Scraping Loop ---\n",
    "all_products_raw = []\n",
    "current_page = 1\n",
    "total_pages = 1 \n",
    "\n",
    "while current_page <= total_pages:\n",
    "    print(f\"Scraping product listing page {current_page}...\")\n",
    "\n",
    "    request_params = base_params.copy()\n",
    "    request_params['page'] = current_page\n",
    "\n",
    "    try:\n",
    "        # Use session.get() instead of requests.get() to utilize retry logic\n",
    "        response = session.get(product_list_base_url, headers=headers, params=request_params)\n",
    "        response.raise_for_status() \n",
    "        data = response.json()\n",
    "\n",
    "        if current_page == 1:\n",
    "            print(\"\\n--- FIRST PRODUCT LISTING PAGE RAW JSON RESPONSE (for debugging) ---\")\n",
    "            print(json.dumps(data, indent=2)[:2000])\n",
    "            print(\"--------------------------------------------------------------------\\n\")\n",
    "\n",
    "        total_count_found = data.get('totalResultCount', 0)\n",
    "        pagination_info = data.get('pagination', {})\n",
    "        total_pages_found = pagination_info.get('totalPages', current_page)\n",
    "        \n",
    "        products_on_page = data.get('plpList', {}).get('productList', []) \n",
    "        \n",
    "        if current_page == 1:\n",
    "            total_count = total_count_found\n",
    "            total_pages = total_pages_found\n",
    "            if total_count == 0 and total_pages > 0 and len(products_on_page) > 0:\n",
    "                 total_count = total_pages * base_params['page-size']\n",
    "            \n",
    "            print(f\"Total products (extracted, potentially estimated): {total_count}, Total pages (extracted): {total_pages}\")\n",
    "            \n",
    "            if not products_on_page and total_count > 0:\n",
    "                print(\"Warning: API returned total products > 0 but no items found on this page via 'plpList.productList'. Exiting.\")\n",
    "                break \n",
    "\n",
    "        all_products_raw.extend(products_on_page)\n",
    "\n",
    "        current_page += 1\n",
    "        time.sleep(0.5)\n",
    "        if current_page > total_pages:\n",
    "            break\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during product listing request on page {current_page}: {e}\")\n",
    "        break \n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON response on page {current_page}. Response content: {response.text[:500]}...\")\n",
    "        break\n",
    "    except KeyError as e:\n",
    "        print(f\"Key error in product listing response on page {current_page}: {e}. Response JSON: {json.dumps(data, indent=2)[:500]}...\")\n",
    "        break\n",
    "\n",
    "print(f\"Finished scraping {len(all_products_raw)} raw product entries.\")\n",
    "\n",
    "# Data Flattening \n",
    "flattened_products = []\n",
    "for i, item in enumerate(tqdm(all_products_raw, desc=\"Fetching Supplier Details\", unit=\"product\")):\n",
    "    product_info = {}\n",
    "\n",
    "    product_info['id'] = item.get('id') \n",
    "    product_info['sku'] = item.get('articleId') \n",
    "    if not product_info['sku']:\n",
    "        product_info['sku'] = item.get('id')\n",
    "        \n",
    "    product_info['name'] = item.get('productName') \n",
    "    product_info['brandName'] = item.get('brandName') \n",
    "    product_info['url'] = item.get('url') \n",
    "    product_info['canonical_url'] = f\"https://www2.hm.com{item.get('url')}\" if item.get('url') else None\n",
    "\n",
    "    prices_list = item.get('prices', [])\n",
    "    if prices_list:\n",
    "        main_price = prices_list[0]\n",
    "        product_info['final_price_value'] = main_price.get('price')\n",
    "        formatted_price = main_price.get('formattedPrice', '')\n",
    "        if formatted_price:\n",
    "            currency_match = re.match(r'^\\W+', formatted_price)\n",
    "            product_info['final_price_currency'] = currency_match.group(0).strip() if currency_match else None\n",
    "        else:\n",
    "            product_info['final_price_currency'] = None\n",
    "\n",
    "        product_info['regular_price_value'] = main_price.get('price')\n",
    "        product_info['regular_price_currency'] = product_info['final_price_currency']\n",
    "\n",
    "    availability_info = item.get('availability', {})\n",
    "    product_info['in_stock'] = availability_info.get('stockState') == 'Available'\n",
    "    product_info['coming_soon'] = availability_info.get('comingSoon')\n",
    "\n",
    "    images_list = item.get('images', [])\n",
    "    image_urls_parsed = [{'url': img.get('url')} for img in images_list]\n",
    "    product_info['all_image_data'] = json.dumps(image_urls_parsed)\n",
    "\n",
    "    swatches_list = item.get('swatches', [])\n",
    "    swatch_data = []\n",
    "    for swatch in swatches_list:\n",
    "        swatch_data.append({\n",
    "            'articleId': swatch.get('articleId'),\n",
    "            'url': f\"https://www2.hm.com{swatch.get('url')}\" if swatch.get('url') else None,\n",
    "            'colorName': swatch.get('colorName'),\n",
    "            'colorCode': swatch.get('colorCode'),\n",
    "            'productImage': swatch.get('productImage')\n",
    "        })\n",
    "    product_info['swatch_data'] = json.dumps(swatch_data)\n",
    "    \n",
    "    product_info['colorName_main'] = item.get('colorName')\n",
    "    product_info['colorCode_main'] = item.get('colorCode')\n",
    "    product_info['colourShades'] = item.get('colourShades')\n",
    "\n",
    "    sizes_list = item.get('sizes', [])\n",
    "    size_data = [{'id': size.get('id'), 'label': size.get('label')} for size in sizes_list]\n",
    "    product_info['available_sizes'] = json.dumps(size_data)\n",
    "\n",
    "    product_info['mainCatCode'] = item.get('mainCatCode')\n",
    "    product_info['sellingAttribute'] = item.get('sellingAttribute')\n",
    "    product_info['newArrival'] = item.get('newArrival')\n",
    "    product_info['isSale'] = item.get('isSale', False)\n",
    "    product_info['modelImage'] = item.get('modelImage')\n",
    "    product_info['colors'] = item.get('colors')\n",
    "\n",
    "    # Supplier Details\n",
    "    supplier_country = None\n",
    "    supplier_name = None\n",
    "    factory_name = None\n",
    "    factory_address = None\n",
    "    workers_number = None\n",
    "\n",
    "    if product_info['sku']: \n",
    "        supplier_detail_url = f\"{supplier_detail_base_url}{product_info['sku']}\"\n",
    "        try:\n",
    "            supplier_response = session.get(supplier_detail_url, headers=headers)\n",
    "            supplier_response.raise_for_status() \n",
    "            supplier_data = supplier_response.json()\n",
    "\n",
    "            countries = supplier_data.get('countries', [])\n",
    "            if countries:\n",
    "                first_country = countries[0]\n",
    "                supplier_country = first_country.get('name')\n",
    "                \n",
    "                suppliers = first_country.get('suppliers', [])\n",
    "                if suppliers:\n",
    "                    first_supplier = suppliers[0]\n",
    "                    supplier_name = first_supplier.get('name')\n",
    "                    \n",
    "                    factories = first_supplier.get('factories', [])\n",
    "                    if factories:\n",
    "                        first_factory = factories[0]\n",
    "                        factory_name = first_factory.get('name')\n",
    "                        factory_address = first_factory.get('address')\n",
    "                        workers_number = first_factory.get('workersNumber')\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            tqdm.write(f\"Error fetching supplier for SKU {product_info['sku']} after {RETRY_MAX} retries: {e}\")\n",
    "        except json.JSONDecodeError:\n",
    "            tqdm.write(f\"Error decoding supplier JSON for SKU {product_info['sku']}. Response: {supplier_response.text[:100]}...\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Unexpected error parsing supplier data for SKU {product_info['sku']}: {e}\")\n",
    "\n",
    "\n",
    "    product_info['supplier_country'] = supplier_country\n",
    "    product_info['supplier_name'] = supplier_name\n",
    "    product_info['factory_name'] = factory_name\n",
    "    product_info['factory_address'] = factory_address\n",
    "    product_info['factory_workers_number'] = workers_number\n",
    "\n",
    "    flattened_products.append(product_info)\n",
    "\n",
    "df = pd.DataFrame(flattened_products)\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "df.to_csv('HnM_CLOTHING_LADIES_INDO_020725.csv.csv', index=False, encoding='utf-8')\n",
    "print(f\"Data saved to HnM_CLOTHING_LADIES_INDO_020725.csv. Total products with data: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
